{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Ynet_QA_RAG_ChatBot**"
      ],
      "metadata": {
        "id": "fgJO3_f3V6a9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TC2ej6Nf-M6_"
      },
      "outputs": [],
      "source": [
        "!pip install gradio langchain langchain-community beautifulsoup4 transformers faiss-cpu sentence-transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import requests\n",
        "import xml.etree.ElementTree as ET\n",
        "from bs4 import BeautifulSoup\n",
        "import json\n",
        "from transformers import AutoTokenizer, AutoModelForQuestionAnswering, pipeline\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_core.documents import Document\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter"
      ],
      "metadata": {
        "id": "9TAw_NW9-NUw"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Global variables\n",
        "vectorstore = None\n",
        "articles = []\n",
        "titles_text = \"\"\n",
        "\n",
        "def scrape_articles_from_rss(rss_url=\"https://www.ynet.co.il/Integration/StoryRss2.xml\", max_articles=5):\n",
        "    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
        "    response = requests.get(rss_url, headers=headers)\n",
        "    root = ET.fromstring(response.content)\n",
        "    items = root.findall(\".//item\")[:max_articles]\n",
        "\n",
        "    articles = []\n",
        "    for item in items:\n",
        "        link = item.find(\"link\").text\n",
        "        title = item.find(\"title\").text if item.find(\"title\") is not None else \"×œ×œ× ×›×•×ª×¨×ª\"\n",
        "        try:\n",
        "            article_resp = requests.get(link, headers=headers)\n",
        "            soup = BeautifulSoup(article_resp.content, 'html.parser')\n",
        "            script = soup.find(\"script\", type=\"application/ld+json\")\n",
        "            article_body = \"\"\n",
        "            if script:\n",
        "                try:\n",
        "                    data = json.loads(script.string)\n",
        "                    if isinstance(data, dict) and \"articleBody\" in data:\n",
        "                        article_body = data[\"articleBody\"]\n",
        "                except:\n",
        "                    pass\n",
        "            if not article_body:\n",
        "                paragraphs = soup.select(\"article p\") or soup.find_all(\"p\")\n",
        "                article_body = ' '.join(p.get_text(strip=True) for p in paragraphs)\n",
        "            if len(article_body.strip()) > 200:\n",
        "                articles.append({'url': link, 'text': article_body, 'title': title})\n",
        "            else:\n",
        "                print(f\"âš ï¸ Skipped short article: {link}\")\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ Error scraping {link}: {e}\")\n",
        "    return articles\n",
        "\n",
        "def initialize_index():\n",
        "    global vectorstore, articles, titles_text\n",
        "\n",
        "    print(\"ğŸ”„ Scraping articles...\")\n",
        "    articles = scrape_articles_from_rss(max_articles=5)\n",
        "    print(f\"âœ… Scraped {len(articles)} articles.\")\n",
        "\n",
        "    docs = [Document(page_content=a['text'], metadata={'url': a['url'], 'title': a['title']}) for a in articles]\n",
        "    splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
        "    split_docs = splitter.split_documents(docs)\n",
        "\n",
        "    print(\"ğŸ”„ Creating embeddings...\")\n",
        "    embedding_model = HuggingFaceEmbeddings(model_name=\"avichr/heBERT\")\n",
        "    vectorstore = FAISS.from_documents(split_docs, embedding_model)\n",
        "    print(\"âœ… Vectorstore ready.\")\n",
        "\n",
        "    titles_text = \"\\n\".join(f\"â€¢ {a['title']}\" for a in articles)\n",
        "\n",
        "def load_qa_model():\n",
        "    model_name = \"deepset/xlm-roberta-large-squad2\"\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    model = AutoModelForQuestionAnswering.from_pretrained(model_name)\n",
        "    qa_pipe = pipeline(\"question-answering\", model=model, tokenizer=tokenizer)\n",
        "    return qa_pipe\n",
        "\n",
        "def answer_question_gradio(query):\n",
        "    related_docs = vectorstore.similarity_search(query, k=1)\n",
        "    if not related_docs:\n",
        "        return \"×œ× × ××¦××• ××××¨×™× ×¨×œ×•×•× ×˜×™×™×.\", \"\"\n",
        "    context = related_docs[0].page_content\n",
        "    url = related_docs[0].metadata.get('url', '')\n",
        "\n",
        "    result = qa_pipe({\n",
        "        \"question\": query,\n",
        "        \"context\": context[:1000]\n",
        "    })\n",
        "\n",
        "    answer = result['answer']\n",
        "    return answer, url\n",
        "\n",
        "def refresh_articles():\n",
        "    initialize_index()\n",
        "    return titles_text\n",
        "\n",
        "# Initial setup\n",
        "initialize_index()\n",
        "qa_pipe = load_qa_model()\n",
        "\n",
        "# UI\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"<h2 style='text-align:right; direction: rtl;'>â“ ×©××œ×•×ª ×•×ª×©×•×‘×•×ª ×¢×œ ×—×“×©×•×ª Ynet ×‘×¢×‘×¨×™×ª</h2>\")\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column(scale=1):\n",
        "            gr.Markdown(\"<h3 style='text-align:right; direction: rtl;'>×›×•×ª×¨×•×ª ×”××××¨×™×:</h3>\")\n",
        "            titles_box = gr.Textbox(value=titles_text, label=\"\", interactive=False, lines=10, elem_id=\"titles_box\")\n",
        "            refresh_btn = gr.Button(\"×¨×¢× ×Ÿ ×—×“×©×•×ª\")\n",
        "\n",
        "        with gr.Column(scale=2):\n",
        "            query_input = gr.Textbox(label=\"×”×§×œ×“ ××ª ×©××œ×ª×š ×›××Ÿ\", lines=3, elem_id=\"query_input\")\n",
        "            answer_output = gr.Textbox(label=\"×ª×©×•×‘×”\", lines=5, elem_id=\"answer_output\", interactive=False)\n",
        "            source_output = gr.Textbox(label=\"×›×ª×•×‘×ª ×”××§×•×¨ ×©×œ ×”××××¨\", interactive=False, elem_id=\"source_output\")\n",
        "            submit_btn = gr.Button(\"×©××œ\")\n",
        "\n",
        "    submit_btn.click(\n",
        "        fn=answer_question_gradio,\n",
        "        inputs=[query_input],\n",
        "        outputs=[answer_output, source_output]\n",
        "    )\n",
        "\n",
        "    refresh_btn.click(\n",
        "        fn=refresh_articles,\n",
        "        inputs=[],\n",
        "        outputs=[titles_box]\n",
        "    )\n",
        "\n",
        "    demo.css = \"\"\"\n",
        "    #query_input textarea, #answer_output textarea, #source_output textarea, #titles_box textarea {\n",
        "        direction: rtl !important;\n",
        "        text-align: right !important;\n",
        "        font-size: 18px !important;\n",
        "        font-family: Arial, sans-serif !important;\n",
        "    }\n",
        "    label {\n",
        "        text-align: right !important;\n",
        "        direction: rtl !important;\n",
        "        width: 100%;\n",
        "        font-size: 18px !important;\n",
        "        font-family: Arial, sans-serif !important;\n",
        "    }\n",
        "    #query_input, #answer_output, #source_output, #titles_box {\n",
        "        margin-left: auto !important;\n",
        "        margin-right: 0 !important;\n",
        "        display: block !important;\n",
        "        width: 100% !important;\n",
        "    }\n",
        "    \"\"\"\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    demo.launch()\n"
      ],
      "metadata": {
        "id": "cJhkaWFVTqau"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}